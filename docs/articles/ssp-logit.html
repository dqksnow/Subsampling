<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>An Introduction to `subsampling` • subsampling</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="An Introduction to `subsampling`">
<meta property="og:description" content="subsampling">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">subsampling</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/ssp-logit.html">An Introduction to `subsampling`</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/dqksnow/Subsampling/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>An Introduction to <code>subsampling</code>
</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/dqksnow/Subsampling/blob/HEAD/vignettes/ssp-logit.Rmd" class="external-link"><code>vignettes/ssp-logit.Rmd</code></a></small>
      <div class="hidden name"><code>ssp-logit.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>A major challenge in big data statistical analysis is the demand for
computing resources. For example, when fitting a logistic regression
model to binary response variable with <span class="math inline">\(N
\times d\)</span> dimensional covariates, the computational complexity
of estimating the coefficients using Newton’s method or the IRLS
algorithm is <span class="math inline">\(O(\zeta N d^2)\)</span>. When
<span class="math inline">\(N\)</span> is large, the time cost can be
unaffordable, especially if high performance computing resource are
unavailable. To address this issue, subsampling has become a widely used
technique to perform the necessary calculations on a subsample drawn
from the full dataset. The computational burden is reduced while having
the efficiency of parameter estimation.</p>
<p>The R package <code>subsampling</code> provides several subsampling
methods and applies them to commonly used statistical models. This
vignette takes logistic regression model as an example of glm to
describe the usage of function <code>ssp.glm</code>. The statistical
theory and algorithms in this implementation are described in references
papers.</p>
<p>The log likelihood function of glm is</p>
<p><span class="math display">\[
\max_{\beta} L(\beta) = \frac{1}{N} \sum_{i=1}^N \left\{y_i
u(\beta^{\top} x_i)
- \psi \left[ u(\beta^{\top} x_i) \right] \right\}.
\]</span> where <span class="math inline">\(u\)</span> and <span class="math inline">\(\psi\)</span> are known functions depend on the
exponential family. For binomial family, the log likelihood function
becomes</p>
<p><span class="math display">\[
\max_{\beta} L(\beta) = \frac{1}{N} \sum_{i=1}^N \left[y_i \beta^{\top}
x_i -
\log\left(1 + e^{\beta^\top x_i}\right) \right].
\]</span></p>
<p>The idea of subsampling methods is as follows: instead of fitting the
model to the size <span class="math inline">\(N\)</span> full dataset,
we first assign a subsampling probability to each observation in the
full dataset. Then we draw a relative small subsample and fit the model
to this subsample. The sampling probabilities are assigned based on the
goal of making the subsample more informative.</p>
</div>
<div class="section level2">
<h2 id="basic-usage-of-ssp-glm">Basic Usage of <code>ssp.glm</code><a class="anchor" aria-label="anchor" href="#basic-usage-of-ssp-glm"></a>
</h2>
<p>We introduce the basic usage by using <code>ssp.glm</code> on a
simulated example data. <span class="math inline">\(X\)</span> contains
<span class="math inline">\(d=6\)</span> covariates which follow
multinormal distribution and <span class="math inline">\(Y\)</span> is
the binary response variable. The full data size is <span class="math inline">\(N = 1 \times 10^4\)</span>.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://yihui.org/knitr/" class="external-link">knitr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/dqksnow/Subsampling" class="external-link">subsampling</a></span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">1e4</span></span>
<span><span class="va">beta0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.5</span>, <span class="fl">7</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">beta0</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span></span>
<span><span class="va">corr</span> <span class="op">&lt;-</span> <span class="fl">0.5</span></span>
<span><span class="va">sigmax</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="va">corr</span>, <span class="va">d</span>, <span class="va">d</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">corr</span>, <span class="va">d</span><span class="op">)</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu">MASS</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html" class="external-link">mvrnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">d</span><span class="op">)</span>, <span class="va">sigmax</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">"V"</span>, <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span>, sep <span class="op">=</span> <span class="st">""</span><span class="op">)</span></span>
<span><span class="va">P</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="fl">1</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">beta0</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">X</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta0</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="va">N</span>, <span class="fl">1</span>, <span class="va">P</span><span class="op">)</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">Y</span>, <span class="va">X</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">formula</span> <span class="op">&lt;-</span> <span class="va">Y</span> <span class="op">~</span> <span class="va">.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="co">#&gt;   Y         V1         V2          V3          V4          V5         V6</span></span>
<span><span class="co">#&gt; 1 1 -1.0918680 -0.4462684 -0.02250989 -0.19626329 -0.67460551 -0.4392570</span></span>
<span><span class="co">#&gt; 2 0 -0.1591053 -0.4748068  0.46515238  0.88370061 -0.05910325  0.1857218</span></span>
<span><span class="co">#&gt; 3 1 -1.6260754 -0.3394421 -0.68490712 -0.55721107  0.01024563 -0.6319413</span></span>
<span><span class="co">#&gt; 4 0  0.1251949  1.5113247  1.38931519  1.24287417  2.48829727  0.5534888</span></span>
<span><span class="co">#&gt; 5 0  0.1931921 -0.1478401 -0.14788926  0.46973556  0.05205022  1.0907459</span></span>
<span><span class="co">#&gt; 6 0 -0.2560258 -1.6065024  0.32710042 -0.04590727 -0.94748664 -1.2310368</span></span></code></pre></div>
<p>The function usage is</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/ssp.glm.html">ssp.glm</a></span><span class="op">(</span></span>
<span>  <span class="va">formula</span>,</span>
<span>  <span class="va">data</span>,</span>
<span>  subset <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  <span class="va">n.plt</span>,</span>
<span>  <span class="va">n.ssp</span>,</span>
<span>  family <span class="op">=</span> <span class="st">"quasibinomial"</span>,</span>
<span>  criterion <span class="op">=</span> <span class="st">"optL"</span>,</span>
<span>  sampling.method <span class="op">=</span> <span class="st">"poisson"</span>,</span>
<span>  likelihood <span class="op">=</span> <span class="st">"weighted"</span>,</span>
<span>  control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">...</span><span class="op">)</span>,</span>
<span>  contrasts <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  <span class="va">...</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
<p>For clarity, we define the terms used in this vignette. The entire
dataset we have on hand is referred to as the “full dataset” and the
estimator derived from this dataset is called the “full data estimator”.
The sample we draw from the full dataset is called the “subsample” and
the corresponding estimator is the “subsample estimator”. The
subsampling probability is denoted as <span class="math inline">\(\pi\)</span>.</p>
<div class="section level3">
<h3 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a>
</h3>
<p>Arguments <code>criterion</code>, <code>sampling.method</code> and
<code>likelihood</code> correspond to three questions:</p>
<ul>
<li><p>How to compute the sampling probability for each
observation?</p></li>
<li><p>How do subsamples be drawn?</p></li>
<li><p>How should the likelihood function be modified to account for the
bias introduced by the subsampling process?</p></li>
</ul>
<div class="section level4">
<h4 id="criterion">
<code>criterion</code><a class="anchor" aria-label="anchor" href="#criterion"></a>
</h4>
<p>The choices of <code>criterion</code> include <code>optA</code>,
<code>optL</code>(default), <code>LCC</code> and
<code>uniform.</code></p>
<ul>
<li><p>optA and optL subsampling criterion were first proposed by <span class="citation">Wang, Zhu, and Ma (2018)</span>. optA subsampling
probabilities are derived by minimizing the trace of the asymptotic
covariance of subsample estimator. optL subsampling probabilities are
derived by minimizing the trace of a transportation of the asymptotic
covariance of subsample estimator. The computational complexity of optA
subsampling probabilities is <span class="math inline">\(O(N
d^2)\)</span> while that of optL is <span class="math inline">\(O(N
d)\)</span>.</p></li>
<li><p><code>LCC</code> stands for the subsampling probability proposed
by <span class="citation">Fithian and Hastie (2014)</span>, serving as a
baseline criterion.</p></li>
<li><p><code>uniform</code> assigns each observation with equal
subsampling probability <span class="math inline">\(\frac{1}{N}\)</span>, serving as a baseline
criterion.</p></li>
</ul>
<p>A pilot estimator for the unknown parameter <span class="math inline">\(\beta\)</span> is required because optA and optL
subsampling probabilities depend on <span class="math inline">\(\beta\)</span>. Yes, no free lunch when it comes
to the optimal subsampling probabilities. Fortunately we only need the
pilot estimator to satisfy some mild conditions. For logistic
regression, this is achieved by drawing a size <code>n.plt</code>
subsample with replacement from full dataset. The case-control subsample
probability is applied, that is, <span class="math inline">\(\pi_i =
\frac{1}{2N_1}\)</span> for <span class="math inline">\(Y_i=1\)</span>
and <span class="math inline">\(\pi_i = \frac{1}{2N_0}\)</span> for
<span class="math inline">\(Y_i=0\)</span>, <span class="math inline">\(i=1,...,N\)</span>, where <span class="math inline">\(N_0\)</span> is the count of <span class="math inline">\(Y=0\)</span> and <span class="math inline">\(N_1 =
N - N_0\)</span>. For other families in glm, uniform subsampling
probability is used. Typically, <code>n.plt</code> is relatively small
compared to <code>n.ssp</code>.</p>
</div>
<div class="section level4">
<h4 id="sampling-method">
<code>sampling.method</code><a class="anchor" aria-label="anchor" href="#sampling-method"></a>
</h4>
<p>The options for the <code>sampling.method</code> argument include
<code>withReplacement</code> and <code>poisson</code> (default).
<code>withReplacement.</code> stands for drawing <span class="math inline">\(n.ssp\)</span> subsamples from full dataset of
size <span class="math inline">\(N\)</span> with replacement, using the
specified subsampling probability. <code>poisson</code> stands for
drawing subsamples one by one by comparing the subsampling probability
with a realization of uniform random variable <span class="math inline">\(U(0,1)\)</span>. The expected number of drawed
samples are <span class="math inline">\(n.ssp\)</span>.</p>
<p>The main differences are:</p>
<ul>
<li><p><code>withReplacement</code> draws exactly <span class="math inline">\(n.ssp\)</span> subsamples while
<code>poisson</code> draws subsamples with expectation <span class="math inline">\(n.ssp\)</span> meaning the actual number may vary
slightly.</p></li>
<li><p><code>withReplacement</code> requires loading the full dataset at
once while <code>poisson</code> allows for scanning the dataset one
observation at a time.</p></li>
<li><p>Theoretical results showed that the <code>poisson</code> method
tends to get a subsample estimator with smaller asymptotic variance
compared to the <code>withReplacement</code> method. See <span class="citation">Wang (2019)</span>.</p></li>
</ul>
</div>
<div class="section level4">
<h4 id="likelihood">
<code>likelihood</code><a class="anchor" aria-label="anchor" href="#likelihood"></a>
</h4>
<p>The available choices for <code>likelihood</code> include
<code>weighted</code> (default) and <code>logOddsCorrection</code>. The
reason we can’t use an equally weighted likelihood function for the
subsample is that it introduces bias due to the different subsampling
probabilities. Therefore, we need to apply methods to correct the
bias.</p>
<ul>
<li><p><code>weighted</code> refers to the weighted likelihood function
for subsample, where each observation is weighted by the inverse of its
subsampling probability.</p></li>
<li><p><code>logOddsCorrection</code> stands for the conditional
likelihood function for the subsample. “conditional” means that each
element in the likelihood function is the probability of <span class="math inline">\(Y=1\)</span> given that this subsample was
drawn.</p></li>
</ul>
<p>Both of these likelihood functions can derive an unbiased optimal
subsample estimator. Theoretical results indicate that
<code>logOddsCorrection</code> is more efficient than
<code>weighted</code> in the context of logistic regression. See <span class="citation">Wang and Kim (2022)</span>. Intuitively, this can be
understood by considering that subsamples with higher subsample
probabilities are typically more informative but receive smaller weights
in the <code>weighted</code> likelihood function. This is the trade-off
required to correct the bias in the weighted likelihood function.</p>
</div>
<div class="section level4">
<h4 id="control">
<code>control</code><a class="anchor" aria-label="anchor" href="#control"></a>
</h4>
<p>The argument <code>control</code> contains two tuning parameters
<code>alpha</code> and <code>b</code>.</p>
<ul>
<li><p><code>alpha</code> <span class="math inline">\(\in [0,1]\)</span>
is the mixture weights of the user assigned subsampling probability and
uniform subsampling probability. That is, the actual subsample
probability is <span class="math inline">\(\pi = (1-\alpha)\pi^{opt} +
\alpha \pi^{uni}\)</span>. The aim is to protect the subsample estimator
from those subsamples with extreme small subsample probability. The
default value of <code>alpha</code> is 0.</p></li>
<li><p><code>b</code> is also used to constaint the subsample
probability. It can be viewed as the threshold to compress too large
subsample probability. It take values between <span class="math inline">\((0,\frac{N}{n})\)</span>. <code>b</code> close to
0 means subsample probabilities are compressed to uniform probability
<span class="math inline">\(\frac{1}{N}\)</span>. <code>b=2</code> is
the default value and it works well for many cases.</p></li>
</ul>
</div>
</div>
<div class="section level3">
<h3 id="results">Results<a class="anchor" aria-label="anchor" href="#results"></a>
</h3>
<p>After drawing subsamples, <code>ssp.glm</code> utilizes
<code><a href="https://rdrr.io/pkg/survey/man/svyglm.html" class="external-link">survey::svyglm</a></code> to fit the model on the subsample, which
eventually uses <code>glm</code>. Arguments used in <code>svyglm</code>
can be added in <code>ssp.glm</code> through <code>...</code> and will
be passed to <code>svyglm</code>.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n.plt</span> <span class="op">&lt;-</span> <span class="fl">200</span></span>
<span><span class="va">n.ssp</span> <span class="op">&lt;-</span> <span class="fl">600</span></span>
<span><span class="va">ssp.results</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ssp.glm.html">ssp.glm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">formula</span>,</span>
<span>                       data <span class="op">=</span> <span class="va">data</span>,</span>
<span>                       n.plt <span class="op">=</span> <span class="va">n.plt</span>,</span>
<span>                       n.ssp <span class="op">=</span> <span class="va">n.ssp</span>,</span>
<span>                       family <span class="op">=</span> <span class="st">"quasibinomial"</span>,</span>
<span>                       criterion <span class="op">=</span> <span class="st">"optL"</span>,</span>
<span>                       sampling.method <span class="op">=</span> <span class="st">"poisson"</span>,</span>
<span>                       likelihood <span class="op">=</span> <span class="st">"weighted"</span></span>
<span>                       <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">ssp.results</span><span class="op">)</span></span>
<span><span class="co">#&gt; Model Summary</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ssp.glm(formula = formula, data = data, n.plt = n.plt, n.ssp = n.ssp, </span></span>
<span><span class="co">#&gt;     family = "quasibinomial", criterion = "optL", sampling.method = "poisson", </span></span>
<span><span class="co">#&gt;     likelihood = "weighted")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Subsample Size:</span></span>
<span><span class="co">#&gt;                                </span></span>
<span><span class="co">#&gt; 1       Total Sample Size 10000</span></span>
<span><span class="co">#&gt; 2 Expected Subsample Size   600</span></span>
<span><span class="co">#&gt; 3   Actual Subsample Size   651</span></span>
<span><span class="co">#&gt; 4   Unique Subsample Size   651</span></span>
<span><span class="co">#&gt; 5  Expected Subample Rate    6%</span></span>
<span><span class="co">#&gt; 6    Actual Subample Rate 6.51%</span></span>
<span><span class="co">#&gt; 7    Unique Subample Rate 6.51%</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;           Estimate Std. Error z value Pr(&gt;|z|)</span></span>
<span><span class="co">#&gt; Intercept  -0.4092     0.0795 -5.1486  &lt;0.0001</span></span>
<span><span class="co">#&gt; V1         -0.5861     0.0949 -6.1791  &lt;0.0001</span></span>
<span><span class="co">#&gt; V2         -0.4514     0.1066 -4.2343  &lt;0.0001</span></span>
<span><span class="co">#&gt; V3         -0.5557     0.1005 -5.5283  &lt;0.0001</span></span>
<span><span class="co">#&gt; V4         -0.3915     0.1006 -3.8898   0.0001</span></span>
<span><span class="co">#&gt; V5         -0.3732     0.1046 -3.5697   0.0004</span></span>
<span><span class="co">#&gt; V6         -0.6454     0.0969 -6.6589  &lt;0.0001</span></span></code></pre></div>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ssp.results</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ssp.glm.html">ssp.glm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">formula</span>,</span>
<span>                       data <span class="op">=</span> <span class="va">data</span>,</span>
<span>                       n.plt <span class="op">=</span> <span class="va">n.plt</span>,</span>
<span>                       n.ssp <span class="op">=</span> <span class="va">n.ssp</span>,</span>
<span>                       family <span class="op">=</span> <span class="st">"quasibinomial"</span>,</span>
<span>                       criterion <span class="op">=</span> <span class="st">"optA"</span>,</span>
<span>                       sampling.method <span class="op">=</span> <span class="st">"poisson"</span>,</span>
<span>                       likelihood <span class="op">=</span> <span class="st">"logOddsCorrection"</span></span>
<span>                       <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">ssp.results</span><span class="op">)</span></span>
<span><span class="co">#&gt; Model Summary</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ssp.glm(formula = formula, data = data, n.plt = n.plt, n.ssp = n.ssp, </span></span>
<span><span class="co">#&gt;     family = "quasibinomial", criterion = "optA", sampling.method = "poisson", </span></span>
<span><span class="co">#&gt;     likelihood = "logOddsCorrection")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Subsample Size:</span></span>
<span><span class="co">#&gt;                                </span></span>
<span><span class="co">#&gt; 1       Total Sample Size 10000</span></span>
<span><span class="co">#&gt; 2 Expected Subsample Size   600</span></span>
<span><span class="co">#&gt; 3   Actual Subsample Size   589</span></span>
<span><span class="co">#&gt; 4   Unique Subsample Size   589</span></span>
<span><span class="co">#&gt; 5  Expected Subample Rate    6%</span></span>
<span><span class="co">#&gt; 6    Actual Subample Rate 5.89%</span></span>
<span><span class="co">#&gt; 7    Unique Subample Rate 5.89%</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;           Estimate Std. Error z value Pr(&gt;|z|)</span></span>
<span><span class="co">#&gt; Intercept  -0.3925     0.0797 -4.9222  &lt;0.0001</span></span>
<span><span class="co">#&gt; V1         -0.4166     0.0971 -4.2918  &lt;0.0001</span></span>
<span><span class="co">#&gt; V2         -0.4093     0.1005 -4.0709  &lt;0.0001</span></span>
<span><span class="co">#&gt; V3         -0.4910     0.1005 -4.8855  &lt;0.0001</span></span>
<span><span class="co">#&gt; V4         -0.4763     0.0979 -4.8650  &lt;0.0001</span></span>
<span><span class="co">#&gt; V5         -0.5470     0.1022 -5.3511  &lt;0.0001</span></span>
<span><span class="co">#&gt; V6         -0.4769     0.0985 -4.8439  &lt;0.0001</span></span></code></pre></div>
<p>As recommended by <code><a href="https://rdrr.io/pkg/survey/man/svyglm.html" class="external-link">survey::svyglm</a></code>, for binomial family,
please use <code>family=quasibinomial()</code> to avoid a warning issued
by <code>glm</code>. Refer to <a href="https://www.rdocumentation.org/packages/survey/versions/4.4-2/topics/svyglm" class="external-link">svyglm()
help documentation Details</a>. The ‘quasi’ version of the family
objects provide the same point estimates.</p>
<div class="section level4">
<h4 id="returned-object">Returned object<a class="anchor" aria-label="anchor" href="#returned-object"></a>
</h4>
<p><code>ssp.results</code> is an object contains estimation results and
index of drawn subsamples in the full dataset.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">ssp.results</span><span class="op">)</span></span>
<span><span class="co">#&gt;  [1] "model.call"            "beta.plt"              "beta.ssp"             </span></span>
<span><span class="co">#&gt;  [4] "coefficients"          "cov.ssp"               "cov"                  </span></span>
<span><span class="co">#&gt;  [7] "index.plt"             "index"                 "N"                    </span></span>
<span><span class="co">#&gt; [10] "subsample.size.expect" "terms"</span></span></code></pre></div>
<ul>
<li><p><code>index.plt</code> and <code>index</code> are the row index
of drawn pilot subsamples and optimal subsamples in the full data. They
are ready to be used for further analysis or downstream tasks.</p></li>
<li><p><code>beta.ssp</code> is the optimal subsample estimator for
<span class="math inline">\(\beta\)</span> and <code>coefficients</code>
is the linear combination of <code>beta.plt</code> and
<code>beta.ssp</code>. The combine weights depend on the relative size
of <code>n.plt</code> and <code>n.ssp</code> as well as the estimated
covariance matrix of <code>beta.plt</code> and <code>beta.ssp</code>. We
blend the pilot subsample information into optimal subsample estimator
since the pilot subsample has been drawn.</p></li>
<li><p><code>cov.ssp</code> and <code>cov</code> are estimated
covariance matrix of <code>beta.ssp</code> and
<code>coefficients</code>.</p></li>
<li><p><code>subsample.size.expect</code> is the expected subsample size
which is equals to <code>n.ssp</code> when we use <code>ssp.glm</code>.
In some other models like <code>ssp.relogit</code> it might be
different.</p></li>
</ul>
<p>As for the speed, we generate a larger full dataset for comparison.
Running it on different devices may give different results.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">1e6</span></span>
<span><span class="va">beta0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.5</span>, <span class="fl">7</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">beta0</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span></span>
<span><span class="va">corr</span> <span class="op">&lt;-</span> <span class="fl">0.5</span></span>
<span><span class="va">sigmax</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="va">corr</span>, <span class="va">d</span>, <span class="va">d</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">corr</span>, <span class="va">d</span><span class="op">)</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu">MASS</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html" class="external-link">mvrnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">d</span><span class="op">)</span>, <span class="va">sigmax</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">"V"</span>, <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span>, sep <span class="op">=</span> <span class="st">""</span><span class="op">)</span></span>
<span><span class="va">P</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="fl">1</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">beta0</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">X</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta0</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="va">N</span>, <span class="fl">1</span>, <span class="va">P</span><span class="op">)</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">Y</span>, <span class="va">X</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">formula</span> <span class="op">&lt;-</span> <span class="va">Y</span> <span class="op">~</span> <span class="va">.</span></span>
<span><span class="va">n.plt</span> <span class="op">&lt;-</span> <span class="fl">200</span></span>
<span><span class="va">n.ssp</span> <span class="op">&lt;-</span> <span class="fl">1e4</span></span>
<span><span class="va">benchmark_results</span> <span class="op">&lt;-</span> <span class="fu">microbenchmark</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/microbenchmark/man/microbenchmark.html" class="external-link">microbenchmark</a></span><span class="op">(</span></span>
<span>  method1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">formula</span>, </span>
<span>                family<span class="op">=</span><span class="va">binomial</span>, </span>
<span>                data <span class="op">=</span> <span class="va">data</span><span class="op">)</span>,</span>
<span>  method2 <span class="op">=</span> <span class="fu"><a href="../reference/ssp.glm.html">ssp.glm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">formula</span>,</span>
<span>                    data <span class="op">=</span> <span class="va">data</span>,</span>
<span>                    n.plt <span class="op">=</span> <span class="va">n.plt</span>,</span>
<span>                    n.ssp <span class="op">=</span> <span class="va">n.ssp</span>,</span>
<span>                    family <span class="op">=</span> <span class="st">'quasibinomial'</span><span class="op">)</span>,</span>
<span>    method3 <span class="op">=</span> <span class="fu"><a href="../reference/ssp.glm.html">ssp.glm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">formula</span>,</span>
<span>                      data <span class="op">=</span> <span class="va">data</span>,</span>
<span>                      n.plt <span class="op">=</span> <span class="va">n.plt</span>,</span>
<span>                      n.ssp <span class="op">=</span> <span class="va">n.ssp</span>,</span>
<span>                      family <span class="op">=</span> <span class="st">'quasibinomial'</span>,</span>
<span>                      criterion <span class="op">=</span> <span class="st">"uniform"</span><span class="op">)</span>,</span>
<span>  times <span class="op">=</span> <span class="fl">100</span></span>
<span><span class="op">)</span></span>
<span><span class="va">benchmark_results</span></span></code></pre></div>
<table class="table">
<caption>Benchmark results of different methods. Unit:
milliseconds.</caption>
<colgroup>
<col width="10%">
<col width="12%">
<col width="12%">
<col width="12%">
<col width="12%">
<col width="12%">
<col width="12%">
<col width="7%">
<col width="5%">
</colgroup>
<thead><tr>
<th align="left">expr</th>
<th align="right">min</th>
<th align="right">lq</th>
<th align="right">mean</th>
<th align="right">median</th>
<th align="right">uq</th>
<th align="right">max</th>
<th align="right">neval</th>
<th align="left">cld</th>
</tr></thead>
<tbody>
<tr>
<td align="left">method1</td>
<td align="right">1616.9564</td>
<td align="right">1711.7812</td>
<td align="right">1804.1415</td>
<td align="right">1782.0165</td>
<td align="right">1881.6165</td>
<td align="right">2552.8414</td>
<td align="right">100</td>
<td align="left">a</td>
</tr>
<tr>
<td align="left">method2</td>
<td align="right">394.9121</td>
<td align="right">429.3244</td>
<td align="right">526.5950</td>
<td align="right">557.1033</td>
<td align="right">605.4753</td>
<td align="right">972.5234</td>
<td align="right">100</td>
<td align="left">b</td>
</tr>
<tr>
<td align="left">method3</td>
<td align="right">106.5479</td>
<td align="right">131.5475</td>
<td align="right">158.9776</td>
<td align="right">143.5303</td>
<td align="right">160.0647</td>
<td align="right">331.6736</td>
<td align="right">100</td>
<td align="left">c</td>
</tr>
</tbody>
</table>
</div>
<div class="section level4">
<h4 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h4>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-fithian2014local" class="csl-entry">
Fithian, William, and Trevor Hastie. 2014. <span>“Local Case-Control
Sampling: Efficient Subsampling in Imbalanced Data Sets.”</span>
<em>Annals of Statistics</em> 42 (5): 1693.
</div>
<div id="ref-wang2019more" class="csl-entry">
Wang, HaiYing. 2019. <span>“More Efficient Estimation for Logistic
Regression with Optimal Subsamples.”</span> <em>Journal of Machine
Learning Research</em> 20 (132): 1–59.
</div>
<div id="ref-wang2022maximum" class="csl-entry">
Wang, HaiYing, and Jae Kwang Kim. 2022. <span>“Maximum Sampled
Conditional Likelihood for Informative Subsampling.”</span> <em>Journal
of Machine Learning Research</em> 23 (332): 1–50.
</div>
<div id="ref-wang2018optimal" class="csl-entry">
Wang, HaiYing, Rong Zhu, and Ping Ma. 2018. <span>“Optimal Subsampling
for Large Sample Logistic Regression.”</span> <em>Journal of the
American Statistical Association</em> 113 (522): 829–44.
</div>
</div>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Qingkai Dong, Haiying Wang, Yaqiong Yao, Qiang Zhang, Jun Yan.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
