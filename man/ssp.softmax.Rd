% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/softmax_main_function.R
\name{ssp.softmax}
\alias{ssp.softmax}
\title{Optimal Subsampling Method for Softmax(multinomial logistic) Regression Model}
\usage{
ssp.softmax(
  formula,
  data,
  subset,
  n.plt,
  n.ssp,
  criterion = "MSPE",
  sampling.method = "poisson",
  likelihood = "MSCLE",
  constraint = "summation",
  control = list(...),
  contrasts = NULL,
  ...
)
}
\arguments{
\item{formula}{An object of class "formula" which describes the model to be
fitted.}

\item{data}{A data frame containing the variables in the model.}

\item{subset}{An optional vector specifying a subset of observations to be used.}

\item{n.plt}{The pilot subsample size (the first-step subsample size).
These samples will be used to estimate the pilot estimator as well as to
estimate the optimal subsampling probability.}

\item{n.ssp}{The expectation optimal subsample size (the second-step subsample
size). For \code{sampling.method = 'withReplacement'}, \code{n.ssp} is exactly the subsample size. For \code{sampling.method = 'poisson'}, \code{n.ssp} is the expectation of subsample size.}

\item{criterion}{The criterion of optimal subsampling probabilities.
Choices include \code{optA}, \code{optL}, \code{MSPE}(default), \code{LUC} and \code{uniform}.}

\item{sampling.method}{The sampling method for drawing the optimal subsample.
Choices include \code{withReplacement} and \code{poisson}(default).}

\item{likelihood}{The type of the maximum likelihood function used to
calculate the optimal subsampling estimator. Choices include
\code{weighted} and \code{MSCLE}(default).}

\item{constraint}{The constraint for identifiability of softmax model. Choices include
\code{baseline} and \code{summation}(default).}

\item{control}{A list of parameters for controlling the sampling process. Default is \code{list(alpha=0, b=2)}.}

\item{contrasts}{An optional list. It specifies how categorical variables are represented in the design matrix. For example, \code{contrasts = list(v1 = 'contr.treatment', v2 = 'contr.sum')}.}

\item{...}{A list of parameters which will be passed to \code{nnet::multinom()}.}
}
\value{
ssp.softmax returns an object of class "ssp.softmax" containing the following components (some are optional):
\describe{
\item{model.call}{model call}
\item{coef.plt}{pilot estimator}
\item{coef.ssp}{optimal subsample estimator.}
\item{coef}{weighted combination of \code{coef.plt} and \code{coef.ssp}.}
\item{cov.ssp}{covariance matrix of \code{coef.ssp}}
\item{cov}{covariance matrix of \code{beta.cmb}}
\item{index.plt}{index of pilot subsample in the full sample}
\item{index.ssp}{index of optimal subsample in the full sample}
\item{N}{number of observations in the full sample}
\item{subsample.size.expect}{expected subsample size}
\item{terms}{model terms}
}
}
\description{
Draw subsample from full dataset and fit softmax(multinomial logistic) regression model on subsample.
}
\details{
details TBD

\code{criterion = MSPE} stands for optimal subsampling probabilities by minimizing the Mean Squared Prediction Error which is immune to the choice of model constraint.

In \code{control}, alpha is the mixture proportions of optimal subsampling probability and uniform sampling probability. b is the parameter controls the upper threshold for optimal subsampling probability.
}
\examples{
# softmax regression
d <- 3 # dim of covariates
K <- 2 # K + 1 classes
G <- rbind(rep(-1/(K+1), K), diag(K) - 1/(K+1)) \%x\% diag(d)
N <- 1e4
beta.true.baseline <- cbind(rep(0, d), matrix(-1.5, d, K))
beta.true.summation <- cbind(rep(1, d), 0.5 * matrix(-1, d, K))
set.seed(1)
mu <- rep(0, d)
sigma <- matrix(0.5, nrow = d, ncol = d)
diag(sigma) <- rep(1, d)
X <- MASS::mvrnorm(N, mu, sigma)
prob <- exp( X \%*\% beta.true.summation)
prob <- prob / rowSums(prob)
Y <- apply(prob, 1, function(row) sample(0:K, size = 1, prob = row))
n.plt <- 500
n.ssp <- 1000
data <- as.data.frame(cbind(Y, X))
colnames(data) <- c("Y", paste("V", 1:ncol(X), sep=""))
head(data)
formula <- Y ~ . -1
WithRep.MSPE <- ssp.softmax(formula = formula,
 data = data, 
 n.plt = n.plt,
 n.ssp = n.ssp,
 criterion = 'MSPE', 
 sampling.method = 'withReplacement',
 likelihood = 'weighted',
 constraint = 'baseline')
summary(WithRep.MSPE)
}
\references{
Yao, Y., & Wang, H. (2019). Optimal subsampling for softmax regression. \emph{Statistical Papers}, \strong{60}, 585-599. \url{https://link.springer.com/article/10.1007/s00362-018-01068-6}

Yao, Y., Zou, J., & Wang, H. (2023). Optimal poisson subsampling for softmax regression. \emph{Journal of Systems Science and Complexity}, \strong{36}(4), 1609-1625. \url{https://link.springer.com/article/10.1007/s11424-023-1179-z}

Yao, Y., Zou, J., & Wang, H. (2023). Model constraints independent optimal subsampling probabilities for softmax regression. \emph{Journal of Statistical Planning and Inference}, \strong{225}, 188-201. \doi{https://doi.org/10.1016/j.jspi.2022.12.004}
}
